{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The xGBoost random forest model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics as mr\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV,RandomizedSearchCV, train_test_split,StratifiedKFold\n",
    "import xgboost as gb\n",
    "\n",
    "import utility as util\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workName</th>\n",
       "      <th>overallRating</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8121</td>\n",
       "      <td>Cowboy_Bebop</td>\n",
       "      <td>10</td>\n",
       "      <td>cowboy bebop episodic series episodic mean one...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63480</td>\n",
       "      <td>Utawarerumono</td>\n",
       "      <td>8</td>\n",
       "      <td>utawarerumono manages one harem anime anyone p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8452</td>\n",
       "      <td>Hajime_no_Ippo</td>\n",
       "      <td>10</td>\n",
       "      <td>first let say fan boxing fact pretty much hate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66544</td>\n",
       "      <td>Gensoumaden_Saiyuuki</td>\n",
       "      <td>9</td>\n",
       "      <td>saiyuki one anime grab first episode let go ev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55936</td>\n",
       "      <td>Ranma_½</td>\n",
       "      <td>7</td>\n",
       "      <td>comedy romance based manga rumiko takahashi ra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22039</td>\n",
       "      <td>Kino_no_Tabi__The_Beautiful_World</td>\n",
       "      <td>9</td>\n",
       "      <td>say anime traveler journeying different countr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68626</td>\n",
       "      <td>Kareshi_Kanojo_no_Jijou</td>\n",
       "      <td>8</td>\n",
       "      <td>kare kano romance anime could become incredibl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18797</td>\n",
       "      <td>Hunter_x_Hunter</td>\n",
       "      <td>10</td>\n",
       "      <td>overall best anime actually seen anything else...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43899</td>\n",
       "      <td>Golden_Boy</td>\n",
       "      <td>10</td>\n",
       "      <td>overall honestly really care others opinion an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18796</td>\n",
       "      <td>Hunter_x_Hunter</td>\n",
       "      <td>10</td>\n",
       "      <td>think hear anime people killing poor cute anim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                workName  overallRating  \\\n",
       "id                                                        \n",
       "8121                        Cowboy_Bebop             10   \n",
       "63480                      Utawarerumono              8   \n",
       "8452                      Hajime_no_Ippo             10   \n",
       "66544               Gensoumaden_Saiyuuki              9   \n",
       "55936                            Ranma_½              7   \n",
       "22039  Kino_no_Tabi__The_Beautiful_World              9   \n",
       "68626            Kareshi_Kanojo_no_Jijou              8   \n",
       "18797                    Hunter_x_Hunter             10   \n",
       "43899                         Golden_Boy             10   \n",
       "18796                    Hunter_x_Hunter             10   \n",
       "\n",
       "                                                  review  sentiment  \n",
       "id                                                                   \n",
       "8121   cowboy bebop episodic series episodic mean one...          1  \n",
       "63480  utawarerumono manages one harem anime anyone p...          1  \n",
       "8452   first let say fan boxing fact pretty much hate...          1  \n",
       "66544  saiyuki one anime grab first episode let go ev...          1  \n",
       "55936  comedy romance based manga rumiko takahashi ra...          0  \n",
       "22039  say anime traveler journeying different countr...          1  \n",
       "68626  kare kano romance anime could become incredibl...          1  \n",
       "18797  overall best anime actually seen anything else...          1  \n",
       "43899  overall honestly really care others opinion an...          1  \n",
       "18796  think hear anime people killing poor cute anim...          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv(\"../Datasets/processedAnimeReviews.csv\",index_col = 'id')\n",
    "reviews.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('../Models/w2vmodel.bin')\n",
    "# Get mean feature vector of all words in a sentence\n",
    "def meanFeatureVec(sentence, word_vectors):\n",
    "    word_vecs = [word_vectors[word] for word in word_tokenize(sentence)]\n",
    "    mean_vec = np.asarray(word_vecs).mean(axis=0)\n",
    "    return mean_vec\n",
    "\n",
    "# Takes a dataframe of the reviews and returns a new dataframe of the word embeddings per review\n",
    "def reviewToVectors(sentences, word_vectors):\n",
    "    sent_vecs = [meanFeatureVec(sentence, word_vectors) for sentence in sentences]\n",
    "    df = pd.DataFrame(sent_vecs, index=sentences.index)\n",
    "    return df\n",
    "# Convert reviews to word embeddings\n",
    "X_vectors = reviewToVectors(reviews['review'], w2v_model.wv)\n",
    "# Split into train and test\n",
    "y = reviews['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectors, y, test_size=0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Baseline\n",
    "   All possible parameters for xgboost.XGBClassifier are:\n",
    "   ----------\n",
    "   max_depth : [0,infinity)\n",
    "   \n",
    "       Maximum tree depth for base learners.\n",
    "\n",
    "   learning_rate : float\n",
    "   \n",
    "       Boosting learning rate (xgb's \"eta\")\n",
    "\n",
    "   n_estimators : int\n",
    "   \n",
    "       Number of trees to fit.\n",
    "\n",
    "\n",
    "   objective : string or callable\n",
    "       Specify the learning task and the corresponding learning objective or\n",
    "       a custom objective function to be used. There are \n",
    "\n",
    "   gamma : float\n",
    "       Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "\n",
    "   min_child_weight : int\n",
    "       Minimum sum of instance weight(hessian) needed in a child.\n",
    "\n",
    "   max_delta_step : int\n",
    "       Maximum delta step we allow each tree's weight estimation to be.\n",
    "\n",
    "   subsample : float\n",
    "       Subsample ratio of the training instance.\n",
    "\n",
    "\n",
    "\n",
    "   reg_alpha : float (xgb's alpha)\n",
    "       L1 regularization term on weights\n",
    "\n",
    "   reg_lambda : float (xgb's lambda)\n",
    "       L2 regularization term on weights\n",
    "\n",
    "   scale_pos_weight : float\n",
    "       Balancing of positive and negative weights.\n",
    "\n",
    "   base_score:\n",
    "      The initial prediction score of all instances, global bias.\n",
    "\n",
    "Not all of these paramaters affect accuracy of the model. The relevant once are:\n",
    "\n",
    "Also it is important to note that we only have one X column so :\n",
    "\n",
    "   colsample_bytree : float\n",
    "       Subsample ratio of columns when constructing each tree.\n",
    "\n",
    "   colsample_bylevel : float\n",
    "       Subsample ratio of columns for each level.\n",
    "\n",
    "   colsample_bynode : float\n",
    "       Subsample ratio of columns for each split.\n",
    "       \n",
    "must all be set to 1 which is there default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy', 'recall', 'precision', 'f1', 'roc_auc']\n",
    "#RFModel = gb.XGBRFClassifier()\n",
    "#util.cross_validate_scores(RFModel, X_train, y_train, cv=5, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will test out different objective methods for the XGBClassifier. There are 12 different objective functions\n",
    "we can define. We will break down this report into 12 seperate testing grounds and tweak each parameter for them.\n",
    "The 12 are:\n",
    "\n",
    "reg:squarederror: regression with squared loss. This is the default value\n",
    "\n",
    "reg:logistic: logistic regression\n",
    "\n",
    "binary:logistic: logistic regression for binary classification\n",
    "\n",
    "binary:hinge: hinge loss for binary classification. \n",
    "\n",
    "count:poisson –poisson regression for count data\n",
    "\n",
    "survival:cox: Cox regression for right censored survival time data (negative values are considered right censored). Note that predictions are returned on the hazard ratio scale (i.e., as HR = exp(marginal_prediction) in the proportional hazard function h(t) = h0(t) * HR).\n",
    "\n",
    "multi:softmax: set XGBoost to do multiclass classification using the softmax objective, you also need to set num_class(number of classes)\n",
    "\n",
    "rank:pairwise: Use LambdaMART to perform pairwise ranking where the pairwise loss is minimized\n",
    "\n",
    "rank:ndcg: Use LambdaMART to perform list-wise ranking where Normalized Discounted Cumulative Gain (NDCG) is maximized\n",
    "\n",
    "rank:map: Use LambdaMART to perform list-wise ranking where Mean Average Precision (MAP) is maximized\n",
    "\n",
    "reg:gamma: gamma regression with log-link. \n",
    "\n",
    "reg:tweedie: Tweedie regression with log-link. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will test the baseline for each objective. Then we will break down each objective and do furthur testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Squared Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   29.4s remaining:   44.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores\n",
      "accuracy: 0.7088 (0.0008)\n",
      "recall: 0.8322 (0.0018)\n",
      "precision: 0.7084 (0.0008)\n",
      "f1: 0.7653 (0.0008)\n",
      "roc_auc: 0.7776 (0.0018)\n",
      "\n",
      "Validation Scores\n",
      "accuracy: 0.7061 (0.0037)\n",
      "recall: 0.8301 (0.0052)\n",
      "precision: 0.7063 (0.0025)\n",
      "f1: 0.7632 (0.0033)\n",
      "roc_auc: 0.7730 (0.0032)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   29.7s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.708802</td>\n",
       "      <td>0.706104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.832193</td>\n",
       "      <td>0.830133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.708385</td>\n",
       "      <td>0.706263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.765313</td>\n",
       "      <td>0.763200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.777602</td>\n",
       "      <td>0.773018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  train_score  val_scores\n",
       "0   accuracy     0.708802    0.706104\n",
       "1     recall     0.832193    0.830133\n",
       "2  precision     0.708385    0.706263\n",
       "3         f1     0.765313    0.763200\n",
       "4    roc_auc     0.777602    0.773018"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistical regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   25.1s remaining:   37.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores\n",
      "accuracy: 0.7091 (0.0006)\n",
      "recall: 0.8324 (0.0015)\n",
      "precision: 0.7086 (0.0003)\n",
      "f1: 0.7655 (0.0007)\n",
      "roc_auc: 0.7782 (0.0003)\n",
      "\n",
      "Validation Scores\n",
      "accuracy: 0.7051 (0.0034)\n",
      "recall: 0.8297 (0.0038)\n",
      "precision: 0.7054 (0.0026)\n",
      "f1: 0.7625 (0.0029)\n",
      "roc_auc: 0.7733 (0.0020)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   25.6s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.709100</td>\n",
       "      <td>0.705117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.832405</td>\n",
       "      <td>0.829657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.708624</td>\n",
       "      <td>0.705394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.765543</td>\n",
       "      <td>0.762494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.778242</td>\n",
       "      <td>0.773296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  train_score  val_scores\n",
       "0   accuracy     0.709100    0.705117\n",
       "1     recall     0.832405    0.829657\n",
       "2  precision     0.708624    0.705394\n",
       "3         f1     0.765543    0.762494\n",
       "4    roc_auc     0.778242    0.773296"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistical regression for binary classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   25.6s remaining:   38.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores\n",
      "accuracy: 0.7091 (0.0006)\n",
      "recall: 0.8324 (0.0015)\n",
      "precision: 0.7086 (0.0003)\n",
      "f1: 0.7655 (0.0007)\n",
      "roc_auc: 0.7782 (0.0003)\n",
      "\n",
      "Validation Scores\n",
      "accuracy: 0.7051 (0.0034)\n",
      "recall: 0.8297 (0.0038)\n",
      "precision: 0.7054 (0.0026)\n",
      "f1: 0.7625 (0.0029)\n",
      "roc_auc: 0.7733 (0.0020)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   26.3s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.709100</td>\n",
       "      <td>0.705117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.832405</td>\n",
       "      <td>0.829657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.708624</td>\n",
       "      <td>0.705394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.765543</td>\n",
       "      <td>0.762494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.778242</td>\n",
       "      <td>0.773296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  train_score  val_scores\n",
       "0   accuracy     0.709100    0.705117\n",
       "1     recall     0.832405    0.829657\n",
       "2  precision     0.708624    0.705394\n",
       "3         f1     0.765543    0.762494\n",
       "4    roc_auc     0.778242    0.773296"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification using hinge loss optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   29.6s remaining:   44.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores\n",
      "accuracy: 0.5705 (0.0000)\n",
      "recall: 1.0000 (0.0000)\n",
      "precision: 0.5705 (0.0000)\n",
      "f1: 0.7266 (0.0000)\n",
      "roc_auc: 0.5000 (0.0000)\n",
      "\n",
      "Validation Scores\n",
      "accuracy: 0.5705 (0.0000)\n",
      "recall: 1.0000 (0.0000)\n",
      "precision: 0.5705 (0.0000)\n",
      "f1: 0.7266 (0.0000)\n",
      "roc_auc: 0.5000 (0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   30.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.570540</td>\n",
       "      <td>0.570540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.570540</td>\n",
       "      <td>0.570540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.726552</td>\n",
       "      <td>0.726552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  train_score  val_scores\n",
       "0   accuracy     0.570540    0.570540\n",
       "1     recall     1.000000    1.000000\n",
       "2  precision     0.570540    0.570540\n",
       "3         f1     0.726552    0.726552\n",
       "4    roc_auc     0.500000    0.500000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisson regression for count data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   26.0s remaining:   39.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores\n",
      "accuracy: 0.7086 (0.0011)\n",
      "recall: 0.8205 (0.0027)\n",
      "precision: 0.7124 (0.0006)\n",
      "f1: 0.7626 (0.0012)\n",
      "roc_auc: 0.7772 (0.0011)\n",
      "\n",
      "Validation Scores\n",
      "accuracy: 0.7046 (0.0025)\n",
      "recall: 0.8172 (0.0029)\n",
      "precision: 0.7092 (0.0022)\n",
      "f1: 0.7594 (0.0020)\n",
      "roc_auc: 0.7725 (0.0022)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   28.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.708598</td>\n",
       "      <td>0.704567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.820462</td>\n",
       "      <td>0.817210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.712410</td>\n",
       "      <td>0.709245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.762626</td>\n",
       "      <td>0.759406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.777152</td>\n",
       "      <td>0.772529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  train_score  val_scores\n",
       "0   accuracy     0.708598    0.704567\n",
       "1     recall     0.820462    0.817210\n",
       "2  precision     0.712410    0.709245\n",
       "3         f1     0.762626    0.759406\n",
       "4    roc_auc     0.777152    0.772529"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival Cox Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   25.8s remaining:   38.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores\n",
      "accuracy: 0.5705 (0.0000)\n",
      "recall: 1.0000 (0.0000)\n",
      "precision: 0.5705 (0.0000)\n",
      "f1: 0.7266 (0.0000)\n",
      "roc_auc: 0.4835 (0.0197)\n",
      "\n",
      "Validation Scores\n",
      "accuracy: 0.5705 (0.0000)\n",
      "recall: 1.0000 (0.0000)\n",
      "precision: 0.5705 (0.0000)\n",
      "f1: 0.7266 (0.0000)\n",
      "roc_auc: 0.4841 (0.0185)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   26.4s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.570540</td>\n",
       "      <td>0.570540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.570540</td>\n",
       "      <td>0.570540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.726552</td>\n",
       "      <td>0.726552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.483459</td>\n",
       "      <td>0.484136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  train_score  val_scores\n",
       "0   accuracy     0.570540    0.570540\n",
       "1     recall     1.000000    1.000000\n",
       "2  precision     0.570540    0.570540\n",
       "3         f1     0.726552    0.726552\n",
       "4    roc_auc     0.483459    0.484136"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification by optimizing softmax objective\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   44.1s remaining:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores\n",
      "accuracy: 0.7091 (0.0006)\n",
      "recall: 0.8324 (0.0015)\n",
      "precision: 0.7086 (0.0003)\n",
      "f1: 0.7655 (0.0007)\n",
      "roc_auc: 0.6888 (0.0005)\n",
      "\n",
      "Validation Scores\n",
      "accuracy: 0.7051 (0.0034)\n",
      "recall: 0.8297 (0.0038)\n",
      "precision: 0.7054 (0.0026)\n",
      "f1: 0.7625 (0.0029)\n",
      "roc_auc: 0.6847 (0.0035)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   45.4s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.709096</td>\n",
       "      <td>0.705117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.832395</td>\n",
       "      <td>0.829657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.708623</td>\n",
       "      <td>0.705394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.765538</td>\n",
       "      <td>0.762494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.688844</td>\n",
       "      <td>0.684661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  train_score  val_scores\n",
       "0   accuracy     0.709096    0.705117\n",
       "1     recall     0.832395    0.829657\n",
       "2  precision     0.708623    0.705394\n",
       "3         f1     0.765538    0.762494\n",
       "4    roc_auc     0.688844    0.684661"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank Pairwise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   27.3s remaining:   41.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores\n",
      "accuracy: 0.6877 (0.0027)\n",
      "recall: 0.6795 (0.0110)\n",
      "precision: 0.7497 (0.0028)\n",
      "f1: 0.7128 (0.0050)\n",
      "roc_auc: 0.7603 (0.0021)\n",
      "\n",
      "Validation Scores\n",
      "accuracy: 0.6842 (0.0028)\n",
      "recall: 0.6769 (0.0105)\n",
      "precision: 0.7461 (0.0033)\n",
      "f1: 0.7098 (0.0048)\n",
      "roc_auc: 0.7566 (0.0023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   28.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.687655</td>\n",
       "      <td>0.684207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.676948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.749680</td>\n",
       "      <td>0.746086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.712793</td>\n",
       "      <td>0.709774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.760333</td>\n",
       "      <td>0.756579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  train_score  val_scores\n",
       "0   accuracy     0.687655    0.684207\n",
       "1     recall     0.679487    0.676948\n",
       "2  precision     0.749680    0.746086\n",
       "3         f1     0.712793    0.709774\n",
       "4    roc_auc     0.760333    0.756579"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank ndcg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   16.4s remaining:   24.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores\n",
      "accuracy: 0.4295 (0.0000)\n",
      "recall: 0.0000 (0.0000)\n",
      "precision: 0.0000 (0.0000)\n",
      "f1: 0.0000 (0.0000)\n",
      "roc_auc: 0.5000 (0.0000)\n",
      "\n",
      "Validation Scores\n",
      "accuracy: 0.4295 (0.0000)\n",
      "recall: 0.0000 (0.0000)\n",
      "precision: 0.0000 (0.0000)\n",
      "f1: 0.0000 (0.0000)\n",
      "roc_auc: 0.5000 (0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   17.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.42946</td>\n",
       "      <td>0.42946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  train_score  val_scores\n",
       "0   accuracy      0.42946     0.42946\n",
       "1     recall      0.00000     0.00000\n",
       "2  precision      0.00000     0.00000\n",
       "3         f1      0.00000     0.00000\n",
       "4    roc_auc      0.50000     0.50000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank map\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   14.0s remaining:   21.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores\n",
      "accuracy: 0.4295 (0.0000)\n",
      "recall: 0.0000 (0.0000)\n",
      "precision: 0.0000 (0.0000)\n",
      "f1: 0.0000 (0.0000)\n",
      "roc_auc: 0.5000 (0.0000)\n",
      "\n",
      "Validation Scores\n",
      "accuracy: 0.4295 (0.0000)\n",
      "recall: 0.0000 (0.0000)\n",
      "precision: 0.0000 (0.0000)\n",
      "f1: 0.0000 (0.0000)\n",
      "roc_auc: 0.5000 (0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.7s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.42946</td>\n",
       "      <td>0.42946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  train_score  val_scores\n",
       "0   accuracy      0.42946     0.42946\n",
       "1     recall      0.00000     0.00000\n",
       "2  precision      0.00000     0.00000\n",
       "3         f1      0.00000     0.00000\n",
       "4    roc_auc      0.50000     0.50000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression gamma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   27.4s remaining:   41.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores\n",
      "accuracy: 0.7076 (0.0009)\n",
      "recall: 0.7721 (0.0016)\n",
      "precision: 0.7307 (0.0009)\n",
      "f1: 0.7508 (0.0008)\n",
      "roc_auc: 0.7732 (0.0018)\n",
      "\n",
      "Validation Scores\n",
      "accuracy: 0.7028 (0.0028)\n",
      "recall: 0.7678 (0.0039)\n",
      "precision: 0.7268 (0.0018)\n",
      "f1: 0.7467 (0.0028)\n",
      "roc_auc: 0.7685 (0.0027)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   28.6s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.707631</td>\n",
       "      <td>0.702849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.772067</td>\n",
       "      <td>0.767781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.730726</td>\n",
       "      <td>0.726795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.750827</td>\n",
       "      <td>0.746724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.773224</td>\n",
       "      <td>0.768475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  train_score  val_scores\n",
       "0   accuracy     0.707631    0.702849\n",
       "1     recall     0.772067    0.767781\n",
       "2  precision     0.730726    0.726795\n",
       "3         f1     0.750827    0.746724\n",
       "4    roc_auc     0.773224    0.768475"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression tweedie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   34.4s remaining:   51.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores\n",
      "accuracy: 0.7096 (0.0018)\n",
      "recall: 0.8008 (0.0036)\n",
      "precision: 0.7211 (0.0020)\n",
      "f1: 0.7589 (0.0016)\n",
      "roc_auc: 0.7763 (0.0015)\n",
      "\n",
      "Validation Scores\n",
      "accuracy: 0.7063 (0.0033)\n",
      "recall: 0.7986 (0.0039)\n",
      "precision: 0.7182 (0.0030)\n",
      "f1: 0.7563 (0.0027)\n",
      "roc_auc: 0.7725 (0.0015)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   34.8s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.709642</td>\n",
       "      <td>0.706317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.800805</td>\n",
       "      <td>0.798611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.721112</td>\n",
       "      <td>0.718205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.758865</td>\n",
       "      <td>0.756271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.776294</td>\n",
       "      <td>0.772498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric  train_score  val_scores\n",
       "0   accuracy     0.709642    0.706317\n",
       "1     recall     0.800805    0.798611\n",
       "2  precision     0.721112    0.718205\n",
       "3         f1     0.758865    0.756271\n",
       "4    roc_auc     0.776294    0.772498"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SquaredError = gb.XGBClassifier(objective = \"reg:squarederror\",n_estimators =  10) \n",
    "Logistic = gb.XGBClassifier(objective = \"reg:logistic\",n_estimators =  10) \n",
    "BinaryLogistic = gb.XGBClassifier(objective = \"binary:logistic\",n_estimators =  10) \n",
    "BinaryHinge = gb.XGBClassifier(objective = \"binary:hinge\",n_estimators =  10) \n",
    "CountPoisson = gb.XGBClassifier(objective = \"count:poisson\",n_estimators =  10) \n",
    "SurvivalCox = gb.XGBClassifier(objective = \"survival:cox\",n_estimators =  10) \n",
    "MultiSoftMax = gb.XGBClassifier(objective = \"multi:softmax\", num_class = 2,n_estimators =  10) \n",
    "RankPairWise = gb.XGBClassifier(objective = \"rank:pairwise\",n_estimators =  10) \n",
    "RankNDCG = gb.XGBClassifier(objective = \"rank:ndcg\",n_estimators =  10) \n",
    "RankMap = gb.XGBClassifier(objective = \"rank:map\",n_estimators =  10) \n",
    "RegGamma = gb.XGBClassifier(objective = \"reg:gamma\",n_estimators =  10) \n",
    "RegTweedie = gb.XGBClassifier(objective = \"reg:tweedie\",n_estimators =  10) \n",
    "\n",
    "print(\"Regression Squared Error\")\n",
    "util.cross_validate_scores(SquaredError, X_train, y_train, cv=5, metrics=metrics)\n",
    "\n",
    "print(\"Logistical regression\")\n",
    "util.cross_validate_scores(Logistic, X_train, y_train, cv=5, metrics=metrics)\n",
    "\n",
    "print(\"Logistical regression for binary classification\")\n",
    "util.cross_validate_scores(BinaryLogistic, X_train, y_train, cv=5, metrics=metrics)\n",
    "\n",
    "print(\"Binary classification using hinge loss optimization\")\n",
    "util.cross_validate_scores(BinaryHinge, X_train, y_train, cv=5, metrics=metrics)\n",
    "\n",
    "print(\"Poisson regression for count data\")\n",
    "util.cross_validate_scores(CountPoisson, X_train, y_train, cv=5, metrics=metrics)\n",
    "\n",
    "print(\"Survival Cox Regression\")\n",
    "util.cross_validate_scores(SurvivalCox, X_train, y_train, cv=5, metrics=metrics)\n",
    "\n",
    "print(\"Classification by optimizing softmax objective\")\n",
    "util.cross_validate_scores(MultiSoftMax, X_train, y_train, cv=5, metrics=metrics)\n",
    "\n",
    "print(\"Rank Pairwise\")\n",
    "util.cross_validate_scores(RankPairWise, X_train, y_train, cv=5, metrics=metrics)\n",
    "\n",
    "print(\"Rank ndcg\")\n",
    "util.cross_validate_scores(RankNDCG, X_train, y_train, cv=5, metrics=metrics)\n",
    "\n",
    "print(\"Rank map\")\n",
    "util.cross_validate_scores(RankMap, X_train, y_train, cv=5, metrics=metrics)\n",
    "\n",
    "print(\"Regression gamma\")\n",
    "util.cross_validate_scores(RegGamma, X_train, y_train, cv=5, metrics=metrics)\n",
    "\n",
    "print(\"Regression tweedie\")\n",
    "util.cross_validate_scores(RegTweedie, X_train, y_train, cv=5, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsoluteBaseline = gb.XGBClassifier() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Squared Error Objective 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:629: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=1, nthread=N...\n",
       "                                                          0.8, 0.9],\n",
       "                                        'max_delta_step': [0],\n",
       "                                        'max_depth': [1, 3, 5, 7, 9, 11],\n",
       "                                        'min_child_weight': [0, 5, 10, 15],\n",
       "                                        'n_estimators': [10],\n",
       "                                        'objective': ['reg:squarederror'],\n",
       "                                        'reg_alpha': [0, 0.001, 0.005, 0.01,\n",
       "                                                      0.05],\n",
       "                                        'reg_lambda': [0, 0.1, 0.3, 0.6, 9],\n",
       "                                        'scale_pos_weight': [0, 0.1, 0.3, 0.6,\n",
       "                                                             9]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametersMSE = {'objective':['reg:squarederror'],\n",
    "              'learning_rate': [x * 0.1 for x in range(0, 10)], #so called `eta` value\n",
    "              'max_depth': [i for i in range(1,12,2)],\n",
    "              'min_child_weight': [i for i in range(0,20,5)],\n",
    "              'n_estimators': [10],\n",
    "              'gamma' : [i for i in range(0,20,5)],\n",
    "              'max_delta_step':[0],\n",
    "              'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05],\n",
    "              'reg_lambda':[0, 0.1, 0.3, 0.6, 9],\n",
    "              'scale_pos_weight':[0, 0.1, 0.3, 0.6, 9]\n",
    "             }\n",
    "clfMSE = RandomizedSearchCV(AbsoluteBaseline, parametersMSE, n_jobs=-1, \n",
    "                   cv=StratifiedKFold(), \n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "clfMSE.fit( X_train,y_train)\n",
    "\n",
    "BestMSEParam = clfMSE.cv_results_['params'][clfMSE.best_index_]\n",
    "BestMSE = clfMSE.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistical regression for binary classification Objective 3\n",
    "This is the exact same for objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:629: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=1, nthread=N...\n",
       "                                                          0.8, 0.9],\n",
       "                                        'max_delta_step': [0],\n",
       "                                        'max_depth': [1, 3, 5, 7, 9, 11],\n",
       "                                        'min_child_weight': [0, 5, 10, 15],\n",
       "                                        'n_estimators': [10],\n",
       "                                        'objective': ['binary:logistic'],\n",
       "                                        'reg_alpha': [0, 0.001, 0.005, 0.01,\n",
       "                                                      0.05],\n",
       "                                        'reg_lambda': [0, 0.1, 0.3, 0.6, 9],\n",
       "                                        'scale_pos_weight': [0, 0.1, 0.3, 0.6,\n",
       "                                                             9]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametersLRB = {'objective':['binary:logistic'],\n",
    "              'learning_rate': [x * 0.1 for x in range(0, 10)], #so called `eta` value\n",
    "              'max_depth': [i for i in range(1,12,2)],\n",
    "              'min_child_weight': [i for i in range(0,20,5)],\n",
    "              'n_estimators': [10],\n",
    "              'gamma' : [i for i in range(0,20,5)],\n",
    "              'max_delta_step':[0],\n",
    "              'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05],\n",
    "              'reg_lambda':[0, 0.1, 0.3, 0.6, 9],\n",
    "              'scale_pos_weight':[0, 0.1, 0.3, 0.6, 9]\n",
    "             }\n",
    "clfLRB = RandomizedSearchCV(AbsoluteBaseline, parametersLRB, n_jobs=-1, \n",
    "                   cv=StratifiedKFold(), \n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "clfLRB.fit( X_train,y_train)\n",
    "\n",
    "BestLogisticRegressionParam = clfLRB.cv_results_['params'][clfLRB.best_index_]\n",
    "BestLogisticRegression = clfLRB.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hinge loss for binary classificative Objective 4\n",
    "\n",
    "$\\ell(y) = \\max(0, 1-t \\cdot y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:629: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=1, nthread=N...\n",
       "                                                          0.8, 0.9],\n",
       "                                        'max_delta_step': [0],\n",
       "                                        'max_depth': [1, 3, 5, 7, 9, 11],\n",
       "                                        'min_child_weight': [0, 5, 10, 15],\n",
       "                                        'n_estimators': [10],\n",
       "                                        'objective': ['binary:hinge'],\n",
       "                                        'reg_alpha': [0, 0.001, 0.005, 0.01,\n",
       "                                                      0.05],\n",
       "                                        'reg_lambda': [0, 0.1, 0.3, 0.6, 9],\n",
       "                                        'scale_pos_weight': [0, 0.1, 0.3, 0.6,\n",
       "                                                             9]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametersHL = {'objective':['binary:hinge'],\n",
    "              'learning_rate': [x * 0.1 for x in range(0, 10)], #so called `eta` value\n",
    "              'max_depth': [i for i in range(1,12,2)],\n",
    "              'min_child_weight': [i for i in range(0,20,5)],\n",
    "              'n_estimators': [10],\n",
    "              'gamma' : [i for i in range(0,20,5)],\n",
    "              'max_delta_step':[0],\n",
    "              'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05],\n",
    "              'reg_lambda':[0, 0.1, 0.3, 0.6, 9],\n",
    "              'scale_pos_weight':[0, 0.1, 0.3, 0.6, 9]\n",
    "             }\n",
    "clfHL = RandomizedSearchCV(AbsoluteBaseline, parametersHL, n_jobs=-1, \n",
    "                   cv=StratifiedKFold(), \n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "clfHL.fit( X_train,y_train)\n",
    "\n",
    "BestHingeLossParam = clfHL.cv_results_['params'][clfHL.best_index_]\n",
    "BestHingeLoss = clfHL.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson regression for count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:629: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=1, nthread=N...\n",
       "                                                          0.8, 0.9],\n",
       "                                        'max_delta_step': [0],\n",
       "                                        'max_depth': [1, 3, 5, 7, 9, 11],\n",
       "                                        'min_child_weight': [0, 5, 10, 15],\n",
       "                                        'n_estimators': [10],\n",
       "                                        'objective': ['count:poisson'],\n",
       "                                        'reg_alpha': [0, 0.001, 0.005, 0.01,\n",
       "                                                      0.05],\n",
       "                                        'reg_lambda': [0, 0.1, 0.3, 0.6, 9],\n",
       "                                        'scale_pos_weight': [0, 0.1, 0.3, 0.6,\n",
       "                                                             9]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametersPRC = {'objective':['count:poisson'],\n",
    "              'learning_rate': [x * 0.1 for x in range(0, 10)], #so called `eta` value\n",
    "              'max_depth': [i for i in range(1,12,2)],\n",
    "              'min_child_weight': [i for i in range(0,20,5)],\n",
    "              'n_estimators': [10],\n",
    "              'gamma' : [i for i in range(0,20,5)],\n",
    "              'max_delta_step':[0],\n",
    "              'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05],\n",
    "              'reg_lambda':[0, 0.1, 0.3, 0.6, 9],\n",
    "              'scale_pos_weight':[0, 0.1, 0.3, 0.6, 9]\n",
    "             }\n",
    "clfPRC = RandomizedSearchCV(AbsoluteBaseline, parametersPRC, n_jobs=-1, \n",
    "                   cv=StratifiedKFold(), \n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "clfPRC.fit( X_train,y_train)\n",
    "\n",
    "BestPossionCountDataParam = clfPRC.cv_results_['params'][clfPRC.best_index_]\n",
    "BestPossionCountData = clfPRC.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survival Cox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:629: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=1, nthread=N...\n",
       "                                                          0.8, 0.9],\n",
       "                                        'max_delta_step': [0],\n",
       "                                        'max_depth': [1, 3, 5, 7, 9, 11],\n",
       "                                        'min_child_weight': [0, 5, 10, 15],\n",
       "                                        'n_estimators': [10],\n",
       "                                        'objective': ['count:poisson'],\n",
       "                                        'reg_alpha': [0, 0.001, 0.005, 0.01,\n",
       "                                                      0.05],\n",
       "                                        'reg_lambda': [0, 0.1, 0.3, 0.6, 9],\n",
       "                                        'scale_pos_weight': [0, 0.1, 0.3, 0.6,\n",
       "                                                             9]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametersSC = {'objective':['survival:cox'],\n",
    "              'learning_rate': [x * 0.1 for x in range(0, 10)], #so called `eta` value\n",
    "              'max_depth': [i for i in range(1,12,2)],\n",
    "              'min_child_weight': [i for i in range(0,20,5)],\n",
    "              'n_estimators': [10],\n",
    "              'gamma' : [i for i in range(0,20,5)],\n",
    "              'max_delta_step':[0],\n",
    "              'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05],\n",
    "              'reg_lambda':[0, 0.1, 0.3, 0.6, 9],\n",
    "              'scale_pos_weight':[0, 0.1, 0.3, 0.6, 9]\n",
    "             }\n",
    "clfSC = RandomizedSearchCV(AbsoluteBaseline, parametersPRC, n_jobs=-1, \n",
    "                   cv=StratifiedKFold(), \n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "clfSC.fit( X_train,y_train)\n",
    "\n",
    "BestSurvivalCoxParam = clfSC.cv_results_['params'][clfSC.best_index_]\n",
    "BestSurvivalCox = clfSC.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi:softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:629: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=1, nthread=N...\n",
       "                                        'max_delta_step': [0],\n",
       "                                        'max_depth': [1, 3, 5, 7, 9, 11],\n",
       "                                        'min_child_weight': [0, 5, 10, 15],\n",
       "                                        'n_estimators': [10], 'num_class': [2],\n",
       "                                        'objective': ['multi:softmax'],\n",
       "                                        'reg_alpha': [0, 0.001, 0.005, 0.01,\n",
       "                                                      0.05],\n",
       "                                        'reg_lambda': [0, 0.1, 0.3, 0.6, 9],\n",
       "                                        'scale_pos_weight': [0, 0.1, 0.3, 0.6,\n",
       "                                                             9]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametersMSM = {'objective':['multi:softmax'],\n",
    "              'learning_rate': [x * 0.1 for x in range(0, 10)], #so called `eta` value\n",
    "              'max_depth': [i for i in range(1,12,2)],\n",
    "              'min_child_weight': [i for i in range(0,20,5)],\n",
    "              'n_estimators': [10],\n",
    "              'gamma' : [i for i in range(0,20,5)],\n",
    "              'max_delta_step':[0],\n",
    "              'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05],\n",
    "              'reg_lambda':[0, 0.1, 0.3, 0.6, 9],\n",
    "              'scale_pos_weight':[0, 0.1, 0.3, 0.6, 9],\n",
    "              'num_class':[2]}\n",
    "clfMSM = RandomizedSearchCV(AbsoluteBaseline, parametersMSM, n_jobs=-1, \n",
    "                   cv=StratifiedKFold(), \n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "clfMSM.fit( X_train,y_train)\n",
    "\n",
    "BestMSMParam = clfMSM.cv_results_['params'][clfMSM.best_index_]\n",
    "BestMSM = clfMSM.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rank pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:629: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=1, nthread=N...\n",
       "                                                          0.8, 0.9],\n",
       "                                        'max_delta_step': [0],\n",
       "                                        'max_depth': [1, 3, 5, 7, 9, 11],\n",
       "                                        'min_child_weight': [0, 5, 10, 15],\n",
       "                                        'n_estimators': [10],\n",
       "                                        'objective': ['rank:pairwise'],\n",
       "                                        'reg_alpha': [0, 0.001, 0.005, 0.01,\n",
       "                                                      0.05],\n",
       "                                        'reg_lambda': [0, 0.1, 0.3, 0.6, 9],\n",
       "                                        'scale_pos_weight': [0, 0.1, 0.3, 0.6,\n",
       "                                                             9]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "parametersRPW = {'objective':['rank:pairwise'],\n",
    "              'learning_rate': [x * 0.1 for x in range(0, 10)], #so called `eta` value\n",
    "              'max_depth': [i for i in range(1,12,2)],\n",
    "              'min_child_weight': [i for i in range(0,20,5)],\n",
    "              'n_estimators': [10],\n",
    "              'gamma' : [i for i in range(0,20,5)],\n",
    "              'max_delta_step':[0],\n",
    "              'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05],\n",
    "              'reg_lambda':[0, 0.1, 0.3, 0.6, 9],\n",
    "              'scale_pos_weight':[0, 0.1, 0.3, 0.6, 9]\n",
    "             }\n",
    "clfRPW = RandomizedSearchCV(AbsoluteBaseline, parametersRPW, n_jobs=-1, \n",
    "                   cv=StratifiedKFold(), \n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "clfRPW.fit( X_train,y_train)\n",
    "\n",
    "BestPairwiseParam = clfRPW.cv_results_['params'][clfRPW.best_index_]\n",
    "BestPairwise = clfRPW.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rank ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parametersNDCG = {'objective':['rank:ndcg'],\n",
    "              'learning_rate': [x * 0.1 for x in range(0, 10)], #so called `eta` value\n",
    "              'max_depth': [i for i in range(1,12,2)],\n",
    "              'min_child_weight': [i for i in range(0,20,5)],\n",
    "              'n_estimators': [10],\n",
    "              'gamma' : [i for i in range(0,20,5)],\n",
    "              'max_delta_step':[0],\n",
    "              'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05],\n",
    "              'reg_lambda':[0, 0.1, 0.3, 0.6, 9],\n",
    "              'scale_pos_weight':[0, 0.1, 0.3, 0.6, 9]\n",
    "             }\n",
    "#clfNDCG = RandomizedSearchCV(AbsoluteBaseline, parametersNDCG, n_jobs=-1, \n",
    "                 #  cv=StratifiedKFold(), \n",
    "                  # scoring='roc_auc',\n",
    "                   #verbose=2, refit=True)\n",
    "\n",
    "#clfNDCG.fit( X_train,y_train)\n",
    "\n",
    "#BestNDCGParam = clfNDCG.cv_results_['params'][clfNDCG.best_index_]\n",
    "#BestNDCG = clfNDCG.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rank map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametersMAP = {'objective':['rank:map'],\n",
    "              'learning_rate': [x * 0.1 for x in range(0, 10)], #so called `eta` value\n",
    "              'max_depth': [i for i in range(1,12,2)],\n",
    "              'min_child_weight': [i for i in range(0,20,5)],\n",
    "              'n_estimators': [10],\n",
    "              'gamma' : [i for i in range(0,20,5)],\n",
    "              'max_delta_step':[0],\n",
    "              'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05],\n",
    "              'reg_lambda':[0, 0.1, 0.3, 0.6, 9],\n",
    "              'scale_pos_weight':[0, 0.1, 0.3, 0.6, 9]\n",
    "             }\n",
    "#clfMAP = RandomizedSearchCV(AbsoluteBaseline, parametersMAP, n_jobs=-1, \n",
    "                   #cv=StratifiedKFold(), \n",
    "                   #scoring='roc_auc',\n",
    "                   #verbose=2, refit=True)\n",
    "\n",
    "#clfMAP.fit( X_train,y_train)\n",
    "\n",
    "#BestMapParam = clfMAP.cv_results_['params'][clfMAP.best_index_]\n",
    "#BestMap = clfMap.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reg gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:629: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\python\\python36\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"c:\\python\\python36\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 600, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"c:\\python\\python36\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"c:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 556, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n  File \"c:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 599, in _score\n    return _multimetric_score(estimator, X_test, y_test, scorer)\n  File \"c:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 629, in _multimetric_score\n    score = scorer(estimator, X_test, y_test)\n  File \"c:\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\scorer.py\", line 207, in __call__\n    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n  File \"c:\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\ranking.py\", line 355, in roc_auc_score\n    sample_weight=sample_weight)\n  File \"c:\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\base.py\", line 76, in _average_binary_score\n    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n  File \"c:\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\ranking.py\", line 327, in _binary_roc_auc_score\n    sample_weight=sample_weight)\n  File \"c:\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\ranking.py\", line 622, in roc_curve\n    y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n  File \"c:\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\ranking.py\", line 402, in _binary_clf_curve\n    assert_all_finite(y_score)\n  File \"c:\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in assert_all_finite\n    _assert_all_finite(X.data if sp.issparse(X) else X, allow_nan)\n  File \"c:\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 56, in _assert_all_finite\n    raise ValueError(msg_err.format(type_err, X.dtype))\nValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-456265e9e97f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                    verbose=2, refit=True)\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mclfGam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mBestGammaParam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclfGam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclfGam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_index_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1469\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    906\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    909\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    552\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    553\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    423\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "parametersGam = {'objective':['reg:gamma'],\n",
    "              'learning_rate': [x * 0.1 for x in range(0, 10)], #so called `eta` value\n",
    "              'max_depth': [i for i in range(1,12,2)],\n",
    "              'min_child_weight': [i for i in range(0,20,5)],\n",
    "              'n_estimators': [10],\n",
    "              'gamma' : [i for i in range(0,20,5)],\n",
    "              'max_delta_step':[0],\n",
    "              'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05],\n",
    "              'reg_lambda':[0, 0.1, 0.3, 0.6, 9],\n",
    "              'scale_pos_weight':[0, 0.1, 0.3, 0.6, 9]\n",
    "             }\n",
    "clfGam = RandomizedSearchCV(AbsoluteBaseline, parametersGam, n_jobs=-1, \n",
    "                   cv=StratifiedKFold(), \n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "clfGam.fit( X_train,y_train)\n",
    "\n",
    "BestGammaParam = clfGam.cv_results_['params'][clfGam.best_index_]\n",
    "BestGamma = clfGam.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reg tweedie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:629: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=1, nthread=N...\n",
       "                                                          0.7000000000000001,\n",
       "                                                          0.8, 0.9],\n",
       "                                        'max_delta_step': [0],\n",
       "                                        'max_depth': [1, 3, 5, 7, 9, 11],\n",
       "                                        'min_child_weight': [0, 5, 10, 15],\n",
       "                                        'n_estimators': [10],\n",
       "                                        'objective': ['reg:tweedie'],\n",
       "                                        'reg_alpha': [0, 0.001, 0.005, 0.01,\n",
       "                                                      0.05],\n",
       "                                        'reg_lambda': [0, 0.1, 0.3, 0.6, 9],\n",
       "                                        'scale_pos_weight': [0, 0.1, 0.3, 0.6,\n",
       "                                                             9]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "NameError",
     "evalue": "name 'clfTwb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-8de8771d1a01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mBestTweedieParam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclfTwd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclfTwd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_index_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mBestTweedie\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclfTwb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clfTwb' is not defined"
     ]
    }
   ],
   "source": [
    "parametersTwd = {'objective':['reg:tweedie'],\n",
    "              'learning_rate': [x * 0.1 for x in range(0, 10)], #so called `eta` value\n",
    "              'max_depth': [i for i in range(1,12,2)],\n",
    "              'min_child_weight': [i for i in range(0,20,5)],\n",
    "              'n_estimators': [10],\n",
    "              'gamma' : [i for i in range(0,20,5)],\n",
    "              'max_delta_step':[0],\n",
    "              'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05],\n",
    "              'reg_lambda':[0, 0.1, 0.3, 0.6, 9],\n",
    "              'scale_pos_weight':[0, 0.1, 0.3, 0.6, 9]\n",
    "             }\n",
    "clfTwd = RandomizedSearchCV(AbsoluteBaseline, parametersTwd, n_jobs=-1, \n",
    "                   cv=StratifiedKFold(), \n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "clfTwd.fit( X_train,y_train)\n",
    "\n",
    "BestTweedieParam = clfTwd.cv_results_['params'][clfTwd.best_index_]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Regression squared error 0.6097344478141874 0.8867041198501873 0.3663915398503998 0.6517126823276284 0.5185252783354627\n",
      "\n",
      "\n",
      "Logistic regression 0.71033360455655 0.8076306508496313 0.6497291720402373 0.7207882633835185 0.720125786163522\n",
      "\n",
      "\n",
      "Binary classification using hinge loss optimization 0.7271987573045343 0.7409338705854468 0.8062935259221047 0.7135543952247123 0.7722332015810275\n",
      "\n",
      "\n",
      "Best Poisson regression for count data 0.7257193579406761 0.7576413652572593 0.7672169202992004 0.7185607585017252 0.76239907727797\n",
      "\n",
      "\n",
      "Best Survival Cox Regression 0.7243878985132036 0.7416026871401151 0.797265927263348 0.7118159644989767 0.7684275947793662\n",
      "\n",
      "\n",
      "Best Rank Pairwise 0.7194319106442785 0.7771092766195606 0.7162754707247873 0.7199764170623069 0.7454533252801825\n",
      "\n",
      "\n",
      "Best Regression tweedie 0.7244618684813966 0.7537473233404711 0.7717307196285788 0.716307684185495 0.7626330210922068\n"
     ]
    }
   ],
   "source": [
    "BestTweedie = clfTwd.best_estimator_\n",
    "def getMetrics(model,y_true,X_test,name):\n",
    "    predictions = model.predict(X_test)\n",
    "    acc = mr.accuracy_score(y_true,predictions)\n",
    "    prec =  mr.precision_score(y_true,predictions)\n",
    "    rec = mr.recall_score(y_true,predictions)\n",
    "    roc_auc = mr.roc_auc_score(y_true,predictions)\n",
    "    f1 = mr.f1_score(y_true,predictions)\n",
    "    print()\n",
    "    print()\n",
    "    print(name,acc,prec,rec,roc_auc,f1)\n",
    "\n",
    "\n",
    "getMetrics(BestMSE,y_test,X_test,\"Regression squared error\")\n",
    "\n",
    "getMetrics(BestLogisticRegression,y_test,X_test,\"Logistic regression\")\n",
    "\n",
    "getMetrics(BestHingeLoss,y_test,X_test,\"Binary classification using hinge loss optimization\")\n",
    "\n",
    "getMetrics(BestPossionCountData,y_test,X_test,\"Best Poisson regression for count data\")\n",
    "\n",
    "getMetrics(BestSurvivalCox,y_test,X_test,\"Best Survival Cox Regression\")\n",
    "\n",
    "\n",
    "getMetrics(BestPairwise,y_test,X_test,\"Best Rank Pairwise\")\n",
    "\n",
    "#getMetrics(BestNDCG,y_test,X_test, \"Best Rank ndcg\")\n",
    "\n",
    "#getMetrics(BestMap ,y_test,X_test,\"Best Rank map\")\n",
    "\n",
    "#getMetrics(BestGamma ,y_test,X_test,\"Best Regression gamma\")\n",
    "\n",
    "getMetrics(BestTweedie ,y_test,X_test, \"Best Regression tweedie\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best Classification by optimizing softmax objective 0.7296397662549005 0.7464822609741432 0.8004900696414754 0.7174176280557767 0.7725434065592133\n"
     ]
    }
   ],
   "source": [
    "getMetrics(BestMSM,y_test,X_test,\"Best Classification by optimizing softmax objective\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
